{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install opencv-python\n",
    "import os\n",
    "import cv2\n",
    "import os\n",
    "import glob\n",
    "import numpy as np\n",
    "from Regressor_Model_Controller import Regressor_Model_Controller\n",
    "import matplotlib.pyplot as plt\n",
    "import torchvision.datasets as datasets\n",
    "import torch\n",
    "import torchvision.transforms as transforms\n",
    "import math\n",
    "import random\n",
    "from CustomData import ImageDataset\n",
    "from utils import Utils\n",
    "\n",
    "\n",
    "torch.set_default_tensor_type(torch.FloatTensor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "DIPALI_HOME = './DLWG/DataSet/*.jpg'\n",
    "IMAGE_HEIGHT = 128\n",
    "IMAGE_WIDTH = 128\n",
    "REGRESSOR_SAVED_MODEL_PATH= './Model/Regressor/Regressor.pth'\n",
    "REGRESSOR_EPOCH = 200\n",
    "REGRESSOR_LOSS_PLOT_PATH = \"./Plots/Regressor/Regressor_Loss_plot\"\n",
    "REGRESSOR_LR = 0.0001\n",
    "REGRESSOR_WEIGHT_DECAY = 1e-5\n",
    "REGRESSOR_IN_CHANNEL = 1\n",
    "REGRESSOR_HIDDEN_CHANNEL = 3\n",
    "REGRESSOR_OUT_DIMS = 2\n",
    "REGRESSOR_BATCH_SIZE_CPU = 32\n",
    "REGRESSOR_BATCH_SIZE_CUDA = 16\n",
    "REGRESSOR_TEST_SPLIT=0.1\n",
    "\n",
    "os.makedirs(\"./Model/Regressor/\", exist_ok=True)\n",
    "os.makedirs(\"./Plots/Regressor/\",exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Use GPU if available"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_device():\n",
    "        device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "        is_cuda_present = True if torch.cuda.is_available() else False\n",
    "        num_workers = 8 if is_cuda_present else 0\n",
    "\n",
    "        return device, is_cuda_present, num_workers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# load augmented image data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_set_dir = './TrainSet'\n",
    "test_data_set_dir = './TestSet'\n",
    "\n",
    "train_image_paths = os.listdir(train_data_set_dir)\n",
    "test_image_paths = os.listdir(test_data_set_dir)\n",
    "\n",
    "train_image_paths = [image_path for image_path in train_image_paths if image_path.endswith('.jpg')]\n",
    "test_image_paths = [image_path for image_path in test_image_paths if image_path.endswith('.jpg')]\n",
    "\n",
    "random.shuffle(train_image_paths)\n",
    "random.shuffle(test_image_paths)\n",
    "\n",
    "train_image_data = [cv2.imread(os.path.join(train_data_set_dir, image_path)) for image_path in train_image_paths]\n",
    "test_image_data = [cv2.imread(os.path.join(test_data_set_dir, image_path)) for image_path in test_image_paths]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Images to  L* a* b* color space convertion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LAB color space\n",
    "train_image_data = [cv2.cvtColor(image, cv2.COLOR_BGR2LAB) for image in train_image_data]\n",
    "test_image_data = [cv2.cvtColor(image, cv2.COLOR_BGR2LAB) for image in test_image_data]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Display L* a* b images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def showImageLab(image_Lab):\n",
    "    #image_bgr = cv2.imread(image_file)\n",
    "    #image_Lab = cv2.cvtColor(image_bgr, cv2.COLOR_BGR2LAB)\n",
    "\n",
    "    L = image_Lab[:, :, 0]\n",
    "    a = image_Lab[:, :, 1]\n",
    "    b = image_Lab[:, :, 2]\n",
    "    print(L)\n",
    "\n",
    "    plt.subplot(1, 3, 1)\n",
    "    plt.title('L')\n",
    "    plt.gray()\n",
    "    plt.imshow(L)\n",
    "    plt.axis('off')\n",
    "\n",
    "    plt.subplot(1, 3, 2)\n",
    "    plt.title('a')\n",
    "    plt.gray()\n",
    "    plt.imshow(a)\n",
    "    plt.axis('off')\n",
    "\n",
    "    plt.subplot(1, 3, 3)\n",
    "    plt.title('b')\n",
    "    plt.gray()\n",
    "    plt.imshow(b)\n",
    "    plt.axis('off')\n",
    "\n",
    "    plt.show() \n",
    "    \n",
    "#print(test_image_data[:5])\n",
    "\n",
    "showImageLab(train_image_data[2])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert images to tensors\n",
    "transform_color = transforms.Compose([transforms.ToTensor()])\n",
    "\n",
    "transformed_train_image_data = []\n",
    "transformed_test_image_data = []\n",
    "\n",
    "for image in train_image_data:\n",
    "    # train image to tensor\n",
    "    image_lab = transform_color(image)\n",
    "    image_gray = image_lab[0:1,:,:]\n",
    "    image_a = image_lab[1:2, :, :]\n",
    "    image_b = image_lab[2:3, :, :]\n",
    "    transformed_train_image_data.append((image_gray, image_a, image_b))\n",
    "\n",
    "for image in test_image_data:\n",
    "    # test image to tensor\n",
    "    image_lab = transform_color(image)\n",
    "    image_gray = image_lab[0:1,:,:]\n",
    "    print(image_gray.shape)\n",
    "    image_a = image_lab[1:2, :, :]\n",
    "    image_b = image_lab[2:3, :, :]\n",
    "    transformed_test_image_data.append((image_gray, image_a, image_b))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(tensor([[[0.0667, 0.0667, 0.0706,  ..., 0.1176, 0.1490, 0.1647],\n",
      "         [0.0706, 0.0745, 0.0745,  ..., 0.1176, 0.1490, 0.1725],\n",
      "         [0.0824, 0.0902, 0.0902,  ..., 0.1176, 0.1490, 0.1765],\n",
      "         ...,\n",
      "         [0.3059, 0.4000, 0.3098,  ..., 0.2353, 0.0588, 0.4588],\n",
      "         [0.3922, 0.4196, 0.3059,  ..., 0.1804, 0.0980, 0.5255],\n",
      "         [0.4784, 0.3843, 0.3255,  ..., 0.0824, 0.2902, 0.6824]]]), tensor([[[0.5098, 0.5098, 0.5098,  ..., 0.5176, 0.5255, 0.5216],\n",
      "         [0.5098, 0.5098, 0.5098,  ..., 0.5176, 0.5216, 0.5216],\n",
      "         [0.5020, 0.5098, 0.5098,  ..., 0.5176, 0.5216, 0.5216],\n",
      "         ...,\n",
      "         [0.5294, 0.5294, 0.5333,  ..., 0.5373, 0.5412, 0.5176],\n",
      "         [0.5294, 0.5294, 0.5294,  ..., 0.5412, 0.5373, 0.5176],\n",
      "         [0.5294, 0.5294, 0.5294,  ..., 0.5490, 0.5255, 0.5137]]]), tensor([[[0.4902, 0.4902, 0.4902,  ..., 0.5137, 0.5137, 0.5216],\n",
      "         [0.4902, 0.4902, 0.4902,  ..., 0.5137, 0.5216, 0.5216],\n",
      "         [0.4902, 0.4902, 0.4902,  ..., 0.5137, 0.5216, 0.5216],\n",
      "         ...,\n",
      "         [0.5176, 0.5176, 0.5176,  ..., 0.5608, 0.5373, 0.5725],\n",
      "         [0.5176, 0.5176, 0.5176,  ..., 0.5686, 0.5569, 0.5765],\n",
      "         [0.5176, 0.5176, 0.5176,  ..., 0.5529, 0.5765, 0.5725]]]))\n"
     ]
    }
   ],
   "source": [
    "transform = transforms.Compose([transforms.ToTensor()])\n",
    "\n",
    "transformed_train_dataset = ImageDataset(root_dir='./TrainSet',\n",
    "                                         transform=transform,\n",
    "                                         regressor_only=True)\n",
    "transformed_test_dataset = ImageDataset(root_dir='./TestSet',\n",
    "                                        transform=transform,\n",
    "                                        regressor_only=True)\n",
    "print(transformed_test_dataset[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train/Test batch data loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_image_data = []\n",
    "test_image_data = []\n",
    "\n",
    "batch_size = REGRESSOR_BATCH_SIZE_CUDA\n",
    "# include both color and gray images\n",
    "trainloader = torch.utils.data.DataLoader(transformed_train_dataset, batch_size=batch_size,\n",
    "                                          shuffle=True, num_workers=0)\n",
    "testloader = torch.utils.data.DataLoader(transformed_test_dataset, batch_size=batch_size,\n",
    "                                         shuffle=False, num_workers=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train the Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_regressor(augmented_dataset_batch, device):\n",
    "        regressor_train_arguments = {\n",
    "            \"data_loader\": augmented_dataset_batch,\n",
    "            \"saved_model_path\": REGRESSOR_SAVED_MODEL_PATH,\n",
    "            \"epochs\": REGRESSOR_EPOCH,\n",
    "            \"learning_rate\": REGRESSOR_LR,\n",
    "            \"weight_decay\": REGRESSOR_WEIGHT_DECAY,\n",
    "            \"in_channel\": REGRESSOR_IN_CHANNEL,\n",
    "            \"hidden_channel\": REGRESSOR_HIDDEN_CHANNEL,\n",
    "            \"out_dims\": REGRESSOR_OUT_DIMS,\n",
    "            \"loss_plot_path\": REGRESSOR_LOSS_PLOT_PATH\n",
    "        }\n",
    "\n",
    "        regressor_manager = Regressor_Model_Controller()\n",
    "        regressor_manager.train(regressor_train_arguments, device)\n",
    "\n",
    "def test_regressor(augmented_dataset_batch, device):\n",
    "        regressor_arguments = {\n",
    "            \"data_loader\": augmented_dataset_batch,\n",
    "            \"saved_model_path\": REGRESSOR_SAVED_MODEL_PATH,\n",
    "            \"in_channel\": REGRESSOR_IN_CHANNEL,\n",
    "            \"hidden_channel\": REGRESSOR_HIDDEN_CHANNEL,\n",
    "            \"out_dims\": REGRESSOR_OUT_DIMS,\n",
    "            \"loss_plot_path\": REGRESSOR_LOSS_PLOT_PATH\n",
    "        }\n",
    "\n",
    "        regressor_manager = Regressor_Model_Controller()\n",
    "        regressor_manager.test(regressor_arguments, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "..Regressor training started..\n",
      "epoch: 0, loss: 0.948368490091525\n",
      "epoch: 1, loss: 0.14347727694257628\n",
      "epoch: 2, loss: 0.098536484692886\n",
      "epoch: 3, loss: 0.07835714912653202\n",
      "epoch: 4, loss: 0.06640737788620754\n",
      "epoch: 5, loss: 0.061646172929613385\n",
      "epoch: 6, loss: 0.05328369171184022\n",
      "epoch: 7, loss: 0.052530278986523626\n",
      "epoch: 8, loss: 0.04928778022076585\n",
      "epoch: 9, loss: 0.04598277894911007\n",
      "epoch: 10, loss: 0.04097573346007266\n",
      "epoch: 11, loss: 0.04475397317764873\n",
      "epoch: 12, loss: 0.03994504684669664\n",
      "epoch: 13, loss: 0.040644261873239884\n",
      "epoch: 14, loss: 0.037996210312485346\n",
      "epoch: 15, loss: 0.036500815527688246\n",
      "epoch: 16, loss: 0.040909150297011365\n",
      "epoch: 17, loss: 0.03646674375522707\n",
      "epoch: 18, loss: 0.039460703354052384\n",
      "epoch: 28, loss: 0.02761747024123906\n",
      "epoch: 29, loss: 0.028205218961375067\n",
      "epoch: 30, loss: 0.028559753383888165\n",
      "epoch: 31, loss: 0.02820867804257432\n",
      "epoch: 32, loss: 0.02701571576471906\n",
      "epoch: 33, loss: 0.025637541941250674\n",
      "epoch: 34, loss: 0.027003439534382778\n",
      "epoch: 35, loss: 0.02708114876804757\n",
      "epoch: 36, loss: 0.024413338543126883\n",
      "epoch: 37, loss: 0.02463726639325614\n",
      "epoch: 38, loss: 0.02522077776484366\n",
      "epoch: 39, loss: 0.02471622566554288\n",
      "epoch: 40, loss: 0.021807906827234547\n",
      "epoch: 41, loss: 0.02342351603510906\n",
      "epoch: 42, loss: 0.020110097209908417\n",
      "epoch: 43, loss: 0.018992899711520295\n",
      "epoch: 44, loss: 0.020943581199389882\n",
      "epoch: 45, loss: 0.01899331539607374\n",
      "epoch: 46, loss: 0.01852860755752772\n",
      "epoch: 47, loss: 0.017635686175708543\n",
      "epoch: 48, loss: 0.015766459340738948\n",
      "epoch: 49, loss: 0.01625878951199411\n",
      "epoch: 50, loss: 0.017352817686514754\n",
      "epoch: 51, loss: 0.016321071876518545\n",
      "epoch: 52, loss: 0.017528084514196962\n",
      "epoch: 53, loss: 0.013926499262197467\n",
      "epoch: 54, loss: 0.014059927981179499\n",
      "epoch: 55, loss: 0.015813735826213815\n",
      "epoch: 56, loss: 0.01483051779359812\n",
      "epoch: 57, loss: 0.013881409903660824\n",
      "epoch: 58, loss: 0.013259623704470869\n",
      "epoch: 59, loss: 0.012829113784391666\n",
      "epoch: 60, loss: 0.012487979610341426\n",
      "epoch: 61, loss: 0.01262496902836574\n",
      "epoch: 62, loss: 0.012481315128752613\n",
      "epoch: 63, loss: 0.012611897941496863\n",
      "epoch: 64, loss: 0.012046486518556776\n",
      "epoch: 65, loss: 0.012085563786968123\n",
      "epoch: 66, loss: 0.012434533072337217\n",
      "epoch: 67, loss: 0.011081570482019742\n",
      "epoch: 68, loss: 0.010925949193733686\n",
      "epoch: 69, loss: 0.011626220661128173\n",
      "epoch: 70, loss: 0.011747072045181994\n",
      "epoch: 71, loss: 0.010818177118380845\n",
      "epoch: 72, loss: 0.01043792492691864\n",
      "epoch: 73, loss: 0.009781188222859782\n",
      "epoch: 74, loss: 0.010688797619877732\n",
      "epoch: 75, loss: 0.010132862335922255\n",
      "epoch: 76, loss: 0.010883186646424292\n",
      "epoch: 77, loss: 0.009803564665162412\n",
      "epoch: 78, loss: 0.009573254302267742\n",
      "epoch: 79, loss: 0.00909775397985868\n",
      "epoch: 80, loss: 0.009692796377748891\n",
      "epoch: 81, loss: 0.009594333461791393\n",
      "epoch: 82, loss: 0.00934599295942462\n",
      "epoch: 83, loss: 0.009073695231563761\n",
      "epoch: 84, loss: 0.009316945514001418\n",
      "epoch: 85, loss: 0.008555055343094864\n",
      "epoch: 86, loss: 0.008721195013094984\n",
      "epoch: 87, loss: 0.008891222166766966\n",
      "epoch: 88, loss: 0.008406300148635637\n",
      "epoch: 89, loss: 0.008144476450070215\n",
      "epoch: 90, loss: 0.008338221283793246\n",
      "epoch: 91, loss: 0.008928881585688941\n",
      "epoch: 92, loss: 0.008754047904858453\n",
      "epoch: 93, loss: 0.007955076530834049\n",
      "epoch: 94, loss: 0.007666299800803245\n",
      "epoch: 95, loss: 0.008336515769315156\n",
      "epoch: 96, loss: 0.00887191178935609\n",
      "epoch: 97, loss: 0.008109098785553215\n",
      "epoch: 98, loss: 0.007708312432441744\n",
      "epoch: 99, loss: 0.007676008050566452\n",
      "epoch: 100, loss: 0.007301222270598373\n",
      "epoch: 101, loss: 0.007803673825492297\n",
      "epoch: 102, loss: 0.008443049136076297\n",
      "epoch: 103, loss: 0.007686378364269331\n",
      "epoch: 104, loss: 0.00760804487617861\n",
      "epoch: 105, loss: 0.007159344335832429\n",
      "epoch: 106, loss: 0.007281676351794886\n",
      "epoch: 107, loss: 0.007444794768616703\n",
      "epoch: 108, loss: 0.00788707958508894\n",
      "epoch: 109, loss: 0.007823662481314386\n",
      "epoch: 110, loss: 0.00778396974919815\n",
      "epoch: 111, loss: 0.007020181121333735\n",
      "epoch: 112, loss: 0.007202168926141894\n",
      "epoch: 113, loss: 0.007676998838178406\n",
      "epoch: 114, loss: 0.007691705731303955\n",
      "epoch: 115, loss: 0.007408111582208221\n",
      "epoch: 116, loss: 0.006865199911317177\n",
      "epoch: 117, loss: 0.007147845838517242\n",
      "epoch: 118, loss: 0.007202264736406505\n",
      "epoch: 119, loss: 0.007383884923456208\n",
      "epoch: 120, loss: 0.00723271074002696\n",
      "epoch: 121, loss: 0.006906602989147359\n",
      "epoch: 122, loss: 0.007104185830485221\n",
      "epoch: 123, loss: 0.00750895722740097\n",
      "epoch: 124, loss: 0.0072125859560401295\n",
      "epoch: 125, loss: 0.007217073388801509\n",
      "epoch: 126, loss: 0.007463365802323096\n",
      "epoch: 127, loss: 0.006839017349193455\n",
      "epoch: 128, loss: 0.00632485533151339\n",
      "epoch: 129, loss: 0.006800651427965931\n",
      "epoch: 130, loss: 0.007398724319273242\n",
      "epoch: 131, loss: 0.007324877996325085\n",
      "epoch: 132, loss: 0.006774354033950658\n",
      "epoch: 133, loss: 0.0068712677498297126\n",
      "epoch: 134, loss: 0.006675384852314892\n",
      "epoch: 135, loss: 0.006805064864693122\n",
      "epoch: 136, loss: 0.00674183575938514\n",
      "epoch: 137, loss: 0.006561293075719732\n",
      "epoch: 138, loss: 0.0070784255522085004\n",
      "epoch: 139, loss: 0.0070137079551386705\n",
      "epoch: 140, loss: 0.006781331980164396\n",
      "epoch: 141, loss: 0.0065914356778193905\n",
      "epoch: 142, loss: 0.006762761427580699\n",
      "epoch: 143, loss: 0.006901229193772451\n",
      "epoch: 144, loss: 0.007028786343653337\n",
      "epoch: 145, loss: 0.006958530281281128\n",
      "epoch: 146, loss: 0.006491305073723197\n",
      "epoch: 147, loss: 0.006277046281411458\n",
      "epoch: 148, loss: 0.006380651673225657\n",
      "epoch: 149, loss: 0.007038368537905626\n",
      "epoch: 150, loss: 0.006803689227581344\n",
      "epoch: 151, loss: 0.006398503327545768\n",
      "epoch: 152, loss: 0.0061757328116982535\n",
      "epoch: 153, loss: 0.006813385783061676\n",
      "epoch: 154, loss: 0.007579428675398958\n",
      "epoch: 155, loss: 0.006902768476265919\n",
      "epoch: 156, loss: 0.006109148536324938\n",
      "epoch: 157, loss: 0.005973998506760836\n",
      "epoch: 158, loss: 0.006378257075539295\n",
      "epoch: 159, loss: 0.007086805535891472\n",
      "epoch: 160, loss: 0.006894190993079974\n",
      "epoch: 161, loss: 0.0066469750099713565\n",
      "epoch: 162, loss: 0.006541315781305457\n",
      "epoch: 163, loss: 0.006368368584844575\n",
      "epoch: 164, loss: 0.006236679445464688\n",
      "epoch: 165, loss: 0.006597651621177647\n",
      "epoch: 166, loss: 0.00712345253350577\n",
      "epoch: 167, loss: 0.006502872239707358\n",
      "epoch: 168, loss: 0.006482044787844643\n",
      "epoch: 169, loss: 0.006055268917407375\n",
      "epoch: 170, loss: 0.006315255076970061\n",
      "epoch: 171, loss: 0.006409802458620106\n",
      "epoch: 172, loss: 0.006491131293842045\n",
      "epoch: 173, loss: 0.006316141125807917\n",
      "epoch: 174, loss: 0.006424257269372902\n",
      "epoch: 175, loss: 0.006403534058790683\n",
      "epoch: 176, loss: 0.0061703301489615114\n",
      "epoch: 177, loss: 0.005975790435059025\n",
      "epoch: 178, loss: 0.0064734524794403114\n",
      "epoch: 179, loss: 0.006639849196290015\n",
      "epoch: 180, loss: 0.006218372940111294\n",
      "epoch: 181, loss: 0.00643194330177721\n",
      "epoch: 182, loss: 0.005909157707719714\n",
      "epoch: 183, loss: 0.005943139781948048\n",
      "epoch: 184, loss: 0.005868488296528085\n",
      "epoch: 185, loss: 0.006320230999335763\n",
      "epoch: 186, loss: 0.006301782715581794\n",
      "epoch: 187, loss: 0.006226699754734\n",
      "epoch: 188, loss: 0.006706947105158179\n",
      "epoch: 189, loss: 0.006424969078125287\n",
      "epoch: 190, loss: 0.006178591876960127\n",
      "epoch: 191, loss: 0.005981891882584023\n",
      "epoch: 192, loss: 0.006254244333376846\n",
      "epoch: 193, loss: 0.006517421893931896\n",
      "epoch: 194, loss: 0.00604514155884317\n",
      "epoch: 195, loss: 0.005960734279597091\n",
      "epoch: 196, loss: 0.006342406776639109\n",
      "epoch: 197, loss: 0.006007432098158461\n",
      "epoch: 198, loss: 0.006218137589712569\n",
      "epoch: 199, loss: 0.006207727353285009\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "device, is_cuda_present, num_workers = Utils.get_device()\n",
    "train_regressor(trainloader,device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_regressor(testloader,device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PyTorch-1.8.1",
   "language": "python",
   "name": "pytorch-1.8.1"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
